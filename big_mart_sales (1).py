# -*- coding: utf-8 -*-
"""Big_Mart_Sales.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1z1_m_L7u9ZncOGZhezUTO-8zQR60KPgf

#IMPORTING THE LIBRARIES
"""

!pip install --upgrade xgboost scikit-learn

import xgboost
import sklearn

print("XGBoost version:", xgboost.__version__)
print("Scikit-learn version:", sklearn.__version__)

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from xgboost.sklearn import XGBRegressor
from sklearn import metrics

"""Loading the Data Sets"""

Big_mart_data=pd.read_csv('/content/Big_Mart_Sales.csv')

Big_mart_data.head()

"""- item type
- outlet size
- outlet location type
- outlet type

"""

Big_mart_data.shape

"""#HADLING MISSING DATA POINTS"""

Big_mart_data.isnull().sum()

Big_mart_data['Item_Weight'].mean()

Big_mart_data['Item_Weight'].fillna(Big_mart_data['Item_Weight'].mean(),inplace=True)

Big_mart_data.isnull().sum()

mode_of_outlet_Size = Big_mart_data.pivot_table(values='Outlet_Size',columns='Outlet_Type',aggfunc=lambda x:x.mode()[0])

print(mode_of_outlet_Size)

missing_values =Big_mart_data['Outlet_Size'].isnull()
print(missing_values)

Big_mart_data.loc[missing_values, 'Outlet_Size'] = Big_mart_data.loc[missing_values, 'Outlet_Type'].apply(lambda x: mode_of_outlet_Size[x])

Big_mart_data.isnull().sum()

"""#DATA ANALYSIS
- VISUVALIZATION
"""

Big_mart_data.describe()

sns.set()

plt.figure(figsize=(6,6))
sns.distplot(Big_mart_data['Item_Weight'])
plt.show()

plt.figure(figsize=(6,6))
sns.histplot(Big_mart_data['Item_Visibility'])
plt.show()

plt.figure(figsize=(30,6))
sns.countplot(data=Big_mart_data,x='Item_Type')
plt.show()

plt.figure(figsize=(30,6))
sns.countplot(data=Big_mart_data,x='Item_Fat_Content')
plt.show()

"""#DATA PREPROCESSING"""

Big_mart_data['Item_Fat_Content'].value_counts()

#corrcting the multi-same catagories
Big_mart_data['Item_Fat_Content']=Big_mart_data['Item_Fat_Content'].replace({'LF':'Low Fat','reg':'Regular','low fat':'Low Fat'})

Big_mart_data['Item_Fat_Content'].value_counts()

#Label Encoding

label_encoder=LabelEncoder()
Big_mart_data['Item_Fat_Content']=label_encoder.fit_transform(Big_mart_data['Item_Fat_Content'])
Big_mart_data['Outlet_Type']=label_encoder.fit_transform(Big_mart_data['Outlet_Type'])
Big_mart_data['Item_Type']=label_encoder.fit_transform(Big_mart_data['Item_Type'])
Big_mart_data['Outlet_Location_Type']=label_encoder.fit_transform(Big_mart_data['Outlet_Location_Type'])
Big_mart_data['Outlet_Size']=label_encoder.fit_transform(Big_mart_data['Outlet_Size'])

Big_mart_data.head()

"""# Data Splidding And MODEL FITTING"""

#saparating features and target /output
X = Big_mart_data.drop(columns=['Item_Outlet_Sales','Outlet_Identifier','Item_Identifier'], axis=1)
Y = Big_mart_data['Item_Outlet_Sales']

print(X)
print(Y)

"""## Splitting the Data"""

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)

print(X.shape, X_train.shape, X_test.shape)

"""
## Machine Learning Model Training

XGBoost Regressor"""

pip install --upgrade xgboost

import warnings
warnings.filterwarnings('ignore', category=FutureWarning)

pip install scikit-learn==1.0.2 xgboost

regressor = XGBRegressor()

regressor.fit(X_train, Y_train)

training_data_prediction = regressor.predict(X_train)
r2_train = metrics.r2_score(Y_train, training_data_prediction)

test_data_prediction = regressor.predict(X_test)
r2_test = metrics.r2_score(Y_test, test_data_prediction)

print('R Squared value for train data = ', r2_train)
print('R Squared value for test data = ', r2_test)